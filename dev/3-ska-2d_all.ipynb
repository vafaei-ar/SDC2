{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:GPU:0']\n",
      "Default GPU Device:/device:GPU:0\n",
      "gpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "# from sklearn.metrics import r2_score\n",
    "from astropy import wcs, coordinates\n",
    "# from matplotlib.colors import LogNorm\n",
    "from scipy.ndimage import gaussian_filter \n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from jax.lib import xla_bridge\n",
    "\n",
    "from utils import *\n",
    "\n",
    "get_available_gpus()\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not in_notebook():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='MODEL ACTIVITY ANALYZER.')\n",
    "    parser.add_argument('--dataset', default='./dataset', type=str, help='path to dataset')\n",
    "    parser.add_argument('-s', default=32, type=int, help='image length')\n",
    "    parser.add_argument('-f', default=5, type=int, help='image length')\n",
    "    parser.add_argument('--fg', default=1, type=int, help='channel grow factor')\n",
    "    parser.add_argument('--bn', default=0, type=int, help='batch norm')\n",
    "    parser.add_argument('--act', default='relu', type=str, help='activation')\n",
    "    parser.add_argument('--cinc', default=0, type=int, help='continuum include?')\n",
    "    parser.add_argument('--BS', default=32, type=int, help='batch norm')\n",
    "    parser.add_argument('--epochs', default=10, type=int, help='batch norm')\n",
    "#     parser.add_argument('--model', default='model file name', type=str, help='model file name')\n",
    "#     parser.add_argument('--bn', default=0, type=int, help='image length')\n",
    "#     parser.add_argument('--prefix', default='', type=str, help='path to save the results')\n",
    "#     parser.add_argument('--restart', action=\"store_true\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    data_path = args.dataset\n",
    "    \n",
    "    nd1 = args.s\n",
    "    nd2 = args.s\n",
    "    nch = args.f\n",
    "    fgrow = args.fg\n",
    "    bnorm = args.bn\n",
    "    lactivation = args.act\n",
    "    cinclude = args.cinc\n",
    "#     restart = args.\n",
    "    EPOCHS = args.epochs\n",
    "    BS = args.BS\n",
    "    \n",
    "#     restart = args.restart\n",
    "\n",
    "else:\n",
    "    data_path = '/home/vafaeisa/scratch/ska/development/'\n",
    "    data_path = '/home/vafaeisa/scratch/ska/development_large/'\n",
    "#     data_path = '/home/vafaeisa/scratch/ska/evaluation/'\n",
    "    nd1,nch = 32,5\n",
    "    nd2 = nd1\n",
    "    fgrow = 1.5\n",
    "    bnorm = 0\n",
    "    lactivation = 'relu'\n",
    "    cinclude = 1\n",
    "    restart = 0\n",
    "    EPOCHS = 1\n",
    "    BS = 32\n",
    "\n",
    "ds = 5\n",
    "dff = 60\n",
    "dsmear = 10\n",
    "\n",
    "if 'development_large' in data_path:\n",
    "    dmode = 'ldev'\n",
    "elif 'development' in data_path:\n",
    "    dmode = 'dev'\n",
    "elif 'evaluation' in data_path:\n",
    "    dmode = 'eval'\n",
    "else:\n",
    "    assert 0,'dmod error!'\n",
    "\n",
    "mname = 's{}-f{}-fg{}-bn{}-{}-c{}/'.format(nd1,nch,fgrow,bnorm,lactivation,cinclude)\n",
    "    \n",
    "Path('models').mkdir(parents=True, exist_ok=True)\n",
    "Path('models/'+mname).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "mpath = 'models/'+mname\n",
    "model_name = mpath+'model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 5)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 32, 32, 21)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 7)    322         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 7)    1330        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 7)    448         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 7)    448         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 11)   704         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 11)   704         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   1600        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   1600        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 11)   1595        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 11)   1595        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 32, 32, 11)   0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 32, 32, 11)   0           conv2d_8[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 7)    700         tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 7)    700         tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 32, 32, 7)    0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 5)    320         tf.__operators__.add_2[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 12,066\n",
      "Trainable params: 12,066\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model = keras.models.load_model(model_name)\n",
    "except:\n",
    "    if cinclude:\n",
    "        model = SimpleConv_count(shape1=(nd1,nd2,nch),shape2=(nd1,nd2,21),n_class=nch,fgrow=fgrow,bnorm=bnorm,lactivation=lactivation)\n",
    "    else:\n",
    "        model = SimpleConv(shape=(nd1,nd2,nch),n_class=nch,fgrow=fgrow,bnorm=bnorm,lactivation=lactivation)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                             initial_learning_rate=1e-3,\n",
    "                             decay_steps=50,\n",
    "                             decay_rate=0.95)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(\n",
    "#     loss=keras.losses.BinaryCrossentropy(),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=opt,\n",
    "#     metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls {data_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: Invalid 'BLANK' keyword in header.  The 'BLANK' keyword is only applicable to integer data, and will be ignored in this HDU. [astropy.io.fits.hdu.image]\n",
      "WARNING:astropy:VerifyWarning: Invalid 'BLANK' keyword in header.  The 'BLANK' keyword is only applicable to integer data, and will be ignored in this HDU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6668, 1286, 1286)\n"
     ]
    }
   ],
   "source": [
    "sky = fits.open(data_path+'sky_{}_v2.fits'.format(dmode))\n",
    "if cinclude:\n",
    "    cont = fits.open(data_path+'cont_{}.fits'.format(dmode))\n",
    "\n",
    "header = sky[0].header\n",
    "sources = pd.read_csv(data_path+'sky_{}_truthcat_v2.txt'.format(dmode),delimiter=' ')\n",
    "sources = sources.sort_values('line_flux_integral',ascending=0).reset_index()\n",
    "\n",
    "dfreq = header['CDELT3']\n",
    "freq0 = header['CRVAL3']\n",
    "# # frequency list in the HI cube\n",
    "nf,nx,ny = sky[0].data.shape\n",
    "freqs = np.arange(freq0,freq0+nf*dfreq,dfreq)\n",
    "fqmhz = freqs/1e6\n",
    "\n",
    "coord_sys = wcs.WCS(header)\n",
    "ra, dec = sources['ra'],sources['dec']\n",
    "num_sources = len(ra)\n",
    "radec_coords = coordinates.SkyCoord(ra=ra, dec=dec, unit='deg', frame='fk5')\n",
    "coords_ar = np.vstack([radec_coords.ra*u.deg, radec_coords.dec*u.deg,\n",
    "                         np.zeros(num_sources)]).T\n",
    "xy_coords = coord_sys.wcs_world2pix(coords_ar, 0)\n",
    "x_coords, y_coords = xy_coords[:,0], xy_coords[:,1]\n",
    "f_coordsf = sources['central_freq']\n",
    "\n",
    "flux_inds = np.argsort(sources['line_flux_integral'].values)[::-1]\n",
    "\n",
    "delta = 1\n",
    "psky = sky[0].data\n",
    "# smoothed_sky = gaussian_filter(sky[0].data,sigma=(3,3,5))\n",
    "print(psky.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| iter: 95.361%   <===============================================   > | loss=0.00 | chunk   0/  4 | epochs:   1/  2 |\r"
     ]
    }
   ],
   "source": [
    "n_epochs = 2\n",
    "\n",
    "dc = 400\n",
    "\n",
    "edges = np.linspace(0,nx-dc,nx//dc).astype(int)\n",
    "edges[-1] = nx-dc\n",
    "\n",
    "gpatch = get_patch((2*dff+1,2*ds+1,2*ds+1),axis=2,sigma0=0.55,muu=0,c=0.4)\n",
    "chunks = np.arange(0,1286,dc)\n",
    "nchunk = len(chunks)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    ichunk = 0\n",
    "    for icube in chunks:\n",
    "        for jcube in chunks:\n",
    "#             print(icube,icube+dc,jcube,jcube+dc)\n",
    "\n",
    "            i1,i2,j1,j2 = icube,icube+dc,jcube,jcube+dc\n",
    "\n",
    "            psky = sky[0].data[:,i1:i2,j1:j2]\n",
    "        \n",
    "            csky = None\n",
    "            if cinclude:\n",
    "                csky = cont[0].data[:,i1:i2,j1:j2]\n",
    "        \n",
    "            ysky = 0.2*psky\n",
    "\n",
    "            for ii in range(sources.shape[0]):\n",
    "#                 print(ii,end='\\r')\n",
    "                source = sources.loc[flux_inds[ii]:flux_inds[ii],:]\n",
    "                ra_s = source['ra'].values\n",
    "                dec_s = source['dec'].values\n",
    "                freq_s = source['central_freq'].values\n",
    "                ra_p,dec_p,freq_p = coord_sys.wcs_world2pix(np.array([ra_s,dec_s,freq_s]).reshape(1,3),0).T.astype(int)\n",
    "                ra_p,dec_p,freq_p = ra_p[0],dec_p[0],freq_p[0]\n",
    "\n",
    "                if i1<ra_p-ds and ra_p+ds<i2 and j1<dec_p-ds and dec_p+ds<j2:\n",
    "                    pass\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                patch = psky[freq_p-dff:freq_p+dff+1,dec_p-ds:dec_p+ds+1,ra_p-ds:ra_p+ds+1]+0\n",
    "\n",
    "                try:\n",
    "                    i = patch\n",
    "                    c = gpatch\n",
    "                    patch = 2*gpatch*patch\n",
    "                    ysky[freq_p-dff:freq_p+dff+1,dec_p-ds:dec_p+ds+1,ra_p-ds:ra_p+ds+1] += patch\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            psky = psky-psky.min()\n",
    "            psky = psky/psky.max()\n",
    "#             psky = np.concatenate([np.zeros((1,dc,dc)),psky,np.zeros((1,dc,dc))],axis=0)\n",
    "            psky = smear(psky,0,dsmear)\n",
    "\n",
    "            ysky = ysky-ysky.min()\n",
    "            ysky = ysky/ysky.max()\n",
    "#             ysky = np.concatenate([np.zeros((1,dc,dc)),ysky,np.zeros((1,dc,dc))],axis=0)\n",
    "            ysky = smear(ysky,0,dsmear)\n",
    "\n",
    "            psky = psky-psky.min()\n",
    "            psky = psky/psky.max()\n",
    "            ysky = ysky-ysky.min()\n",
    "            ysky = ysky/ysky.max()\n",
    "\n",
    "            psky = np.swapaxes(psky,2,0)\n",
    "            ysky = np.swapaxes(ysky,2,0)\n",
    "            if cinclude:\n",
    "                csky = np.swapaxes(csky,2,0)\n",
    "                csky = csky-csky.min()\n",
    "                csky = csky/csky.max()\n",
    "\n",
    "            if cinclude:\n",
    "                def data_provider(n):\n",
    "                    x1,x2,y = [],[],[]\n",
    "                    for i in range(n):\n",
    "                        xp,xc,yp = get_slice(psky,ysky,nd1,nd2,nch,data2=csky)\n",
    "                        x1.append(xp)\n",
    "                        x2.append(xc)\n",
    "                        y.append(yp)\n",
    "                    x1 = np.array(x1)\n",
    "                    x2 = np.array(x2)\n",
    "                    y = np.array(y)\n",
    "                    return x1,x2,y\n",
    "            else:\n",
    "                def data_provider(n):\n",
    "                    x,y = [],[]\n",
    "                    for i in range(n):\n",
    "                        xp,yp = get_slice(psky,ysky,nd1,nd2,nch)\n",
    "                        x.append(xp)\n",
    "                        y.append(yp)\n",
    "                    x = np.array(x)\n",
    "                    y = np.array(y)\n",
    "                    return x,y\n",
    "\n",
    "            n_iter = psky.size//(nd1*nd2*nch)\n",
    "            \n",
    "            losses = []\n",
    "            for i in range(n_iter):\n",
    "                \n",
    "                if cinclude:\n",
    "                    x1,x2,y = data_provider(10)\n",
    "                    loss = model.train_on_batch([x1,x2],y)\n",
    "                else:\n",
    "                    x,y = data_provider(10)\n",
    "                    loss = model.train_on_batch(x,y)\n",
    "                \n",
    "                rept = '| iter: {:5.3f}%   <{:50s}> | loss={:4.2f} | chunk {:3d}/{:3d} | epochs: {:3d}/{:3d} |'\n",
    "                report = rept.format(100*(i+1)/n_iter,int(50*(i+1)/n_iter)*'=',\n",
    "                                     np.mean(loss),\n",
    "                                     ichunk,nchunk,\n",
    "                                     epoch+1,n_epochs)\n",
    "                print(report,end='\\r')\n",
    "                \n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu1",
   "language": "python",
   "name": "gpu1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
